{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38b50ae3-f3a6-47b9-9e4f-9f3ecc936bbc",
   "metadata": {},
   "source": [
    "## Emotion Detection Using Distilbert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "681a3ffc-985e-4a73-ba77-a6b6f771788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7cf81b4-e985-4b4a-8683-ce0925fe5cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import string\n",
    "import alphabet_detector\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import nltk.corpus\n",
    "import seaborn as sn\n",
    "import matplotlib.pylab as plt\n",
    "import cleantext\n",
    "\n",
    "from cleantext import clean\n",
    "from tensorflow import keras\n",
    "from nltk.corpus import stopwords\n",
    "from alphabet_detector import AlphabetDetector\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea8bcaab-0331-4477-a21d-da28e0e49a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ce04c73-9c3e-40b1-9f8a-5b23949050bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.txt', names = ['Sentence', 'Sentiment'], delimiter = ';', encoding='utf-8')\n",
    "df_val = pd.read_csv('val.txt', names = ['Sentence', 'Sentiment'], delimiter = ';', encoding='utf-8')\n",
    "df_test = pd.read_csv('test.txt', names = ['Sentence', 'Sentiment'], delimiter = ';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d664daaa-931d-4cac-9834-6ee39a87325a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 2)\n",
      "(2000, 2)\n",
      "(2000, 2)\n"
     ]
    }
   ],
   "source": [
    "## 20K Data ==> 60% Train, 20% Val, 20% Test\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca2bb093-32e2-43c2-9459-602b140393c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_train, df_val, df_test])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c04517f-72db-4cd9-ba61-7b54a63192cc",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9bea40c-7a36-4e49-b607-6008b4ef03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(nltk.corpus.words.words())\n",
    "stop = stopwords.words('english')\n",
    "def remove_symbols(text):\n",
    "    pattern = r'[' + string.punctuation + ']'\n",
    "    return re.sub(pattern, '', text)\n",
    "\n",
    "def lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_extra_spaces(text):\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    if text[-1] == ' ':\n",
    "        text = text[:-1]\n",
    "    if text[0] == ' ':\n",
    "        text = text[1:]\n",
    "    return text\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return re.sub('[0-9]', '',text)\n",
    "\n",
    "def remove_links(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "def remove_non_ASCII(text):\n",
    "    return re.sub(r'[^\\x00-\\x7f]',r' ',text)\n",
    "\n",
    "def clean_text(text):\n",
    "    #text = re.sub('\\\\n', '', text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_symbols(text)\n",
    "    text = lower_case(text)\n",
    "    text = remove_non_ASCII(text)\n",
    "    text = remove_extra_spaces(text)\n",
    "    text = remove_links(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ca4af09-1e47-41da-8bda-d0f439939c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sentence=df.Sentence.apply(lambda x:clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa7b8621-a31f-42b6-92a2-e3e88088f2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>i just keep feeling like someone is being unki...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>im feeling a little cranky negative after this...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel that i am useful to my people and that ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>im feeling more comfortable with derby i feel ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel all weird when i have to meet w people ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Sentiment\n",
       "0                               i didnt feel humiliated   sadness\n",
       "1     i can go from feeling so hopeless to so damned...   sadness\n",
       "2      im grabbing a minute to post i feel greedy wrong     anger\n",
       "3     i am ever feeling nostalgic about the fireplac...      love\n",
       "4                                  i am feeling grouchy     anger\n",
       "...                                                 ...       ...\n",
       "1995  i just keep feeling like someone is being unki...     anger\n",
       "1996  im feeling a little cranky negative after this...     anger\n",
       "1997  i feel that i am useful to my people and that ...       joy\n",
       "1998  im feeling more comfortable with derby i feel ...       joy\n",
       "1999  i feel all weird when i have to meet w people ...      fear\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50c0b1d0-8017-48b7-b16e-d1a5bde1bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Number_of_Words'] = df.Sentence.apply(lambda x:len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e971f8f-a376-4dd9-b48f-5bcb9245761e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Number_of_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment  \\\n",
       "0                            i didnt feel humiliated   sadness   \n",
       "1  i can go from feeling so hopeless to so damned...   sadness   \n",
       "2   im grabbing a minute to post i feel greedy wrong     anger   \n",
       "3  i am ever feeling nostalgic about the fireplac...      love   \n",
       "4                               i am feeling grouchy     anger   \n",
       "\n",
       "   Number_of_Words  \n",
       "0                4  \n",
       "1               21  \n",
       "2               10  \n",
       "3               18  \n",
       "4                4  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f453604-f241-484c-a876-f072da967b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 0 to 1999\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   Sentence         20000 non-null  object\n",
      " 1   Sentiment        20000 non-null  object\n",
      " 2   Number_of_Words  20000 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 625.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "# Sentinment column is of type object, we will change it to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc5eb628-e0dd-4b9b-bf59-4cca4a3344f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sentiment = df.Sentiment.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a907118-792a-4dc3-8840-6e4f23d8d52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 20000 entries, 0 to 1999\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   Sentence         20000 non-null  object  \n",
      " 1   Sentiment        20000 non-null  category\n",
      " 2   Number_of_Words  20000 non-null  int64   \n",
      "dtypes: category(1), int64(1), object(1)\n",
      "memory usage: 488.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()\n",
    "# Now the sentiment column has been changed to category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0d55f83-be3f-43ed-945b-0a07c12d7199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sadness', 'anger', 'love', 'surprise', 'fear', 'joy']\n",
       "Categories (6, object): ['anger', 'fear', 'joy', 'love', 'sadness', 'surprise']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a0d108c-ea56-4dc1-a63a-ad4d44033537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       4\n",
       "1       4\n",
       "2       0\n",
       "3       3\n",
       "4       0\n",
       "       ..\n",
       "1995    0\n",
       "1996    0\n",
       "1997    2\n",
       "1998    2\n",
       "1999    1\n",
       "Length: 20000, dtype: int8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Easy way to make them numbers without using dictionary\n",
    "df.Sentiment.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "967bbadc-881e-4c56-b2b9-63edfc175cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Sentiment = df.Sentiment.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc15df9f-e5cb-4b1d-b087-d22ef439025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this dictionary to convert them back into code at the end\n",
    "dictionary_classes = {'anger':0, 'fear':1, 'joy':2, 'love':3, 'sadness':4, 'surprise':5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38592a36-92d8-40e2-bfa3-23a14fa8acba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will use this for seq_length later on\n",
    "df.Number_of_Words.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a447fe3b-5127-4e36-8d92-b1bb99f9c949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size = 0.3, random_state=42, stratify=df.Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e00b340e-a200-44df-9d26-60528284d404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14000, 3)\n",
      "(6000, 3)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "247b5c07-305e-4dd7-9a9d-a173bc91c054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Number_of_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>i just keep feeling like someone is being unki...</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>im feeling a little cranky negative after this...</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel that i am useful to my people and that ...</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>im feeling more comfortable with derby i feel ...</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel all weird when i have to meet w people ...</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Sentiment  \\\n",
       "0                               i didnt feel humiliated          4   \n",
       "1     i can go from feeling so hopeless to so damned...          4   \n",
       "2      im grabbing a minute to post i feel greedy wrong          0   \n",
       "3     i am ever feeling nostalgic about the fireplac...          3   \n",
       "4                                  i am feeling grouchy          0   \n",
       "...                                                 ...        ...   \n",
       "1995  i just keep feeling like someone is being unki...          0   \n",
       "1996  im feeling a little cranky negative after this...          0   \n",
       "1997  i feel that i am useful to my people and that ...          2   \n",
       "1998  im feeling more comfortable with derby i feel ...          2   \n",
       "1999  i feel all weird when i have to meet w people ...          1   \n",
       "\n",
       "      Number_of_Words  \n",
       "0                   4  \n",
       "1                  21  \n",
       "2                  10  \n",
       "3                  18  \n",
       "4                   4  \n",
       "...               ...  \n",
       "1995               36  \n",
       "1996               10  \n",
       "1997               18  \n",
       "1998               18  \n",
       "1999               21  \n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a50d1d8-4584-48ec-a7c4-99c75327f00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "## now we use this to one hot encode them\n",
    "#to_categorical(df_train.Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1367ed6-b2d3-445d-9479-96a6d40ed6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertModel: ['classifier', 'dropout_19', 'pre_classifier']\n",
      "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')\n",
    "bert = TFAutoModel.from_pretrained('distilbert-base-uncased-finetuned-sst-2-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "587dd743-ec76-4ce6-9e24-e9be209e1bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To save the tokenizer & bert use:\n",
    "#tokenizer.save_pretrained('BERT_Tokenizer')\n",
    "#bert.save_pretrained('BERT_Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1e216c5-ed6c-4310-8ea9-0d3afb885884",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer(text = df_train.Sentence.tolist(),\n",
    "                    add_special_tokens=True,\n",
    "                    max_length=70,\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    return_tensors='tf',\n",
    "                    return_token_type_ids=False, # Not very important\n",
    "                    return_attention_mask=True,  # Usually good attention mask\n",
    "                    verbose=True)\n",
    "\n",
    "X_test = tokenizer(text = df_test.Sentence.tolist(),\n",
    "                    add_special_tokens=True,\n",
    "                    max_length=70,\n",
    "                    truncation=True,\n",
    "                    padding=True,\n",
    "                    return_tensors='tf',\n",
    "                    return_token_type_ids=False, # Not very important\n",
    "                    return_attention_mask=True,  # Usually good attention mask\n",
    "                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f77adef4-4d51-4b37-8dc5-834a7de8d878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(14000, 70), dtype=int32, numpy=\n",
       "array([[  101,  1045,  2514, ...,     0,     0,     0],\n",
       "       [  101,  1045,  2514, ...,     0,     0,     0],\n",
       "       [  101,  1045,  2514, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  101,  1045,  3294, ...,     0,     0,     0],\n",
       "       [  101, 10047,  2025, ...,     0,     0,     0],\n",
       "       [  101,  1045,  2134, ...,     0,     0,     0]])>, 'attention_mask': <tf.Tensor: shape=(14000, 70), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])>}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77f8fdc9-2c45-461c-bfee-f18b9472890f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96012d6d-6e89-4264-925a-1a562e306d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5535dc73-a837-49af-9aad-717277802901",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 70\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "# embeddings = dbert_model(input_ids,attention_mask = input_mask)[0]\n",
    "\n",
    "\n",
    "embeddings = bert(input_ids,attention_mask = input_mask)[0] #(0 is the last hidden states,1 means pooler_output)\n",
    "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
    "out = Dense(128, activation='relu')(out)\n",
    "out = tf.keras.layers.Dropout(0.1)(out)\n",
    "out = Dense(32,activation = 'relu')(out)\n",
    "\n",
    "y = Dense(6,activation = 'sigmoid')(out)\n",
    "    \n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
    "model.layers[2].trainable = True\n",
    "# for training bert our lr must be so small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "74aff730-91bb-4c9a-aa12-10053d70b7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 70)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 70)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_distil_bert_model (TFDistilB TFBaseModelOutput(la 66362880    input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 768)          0           tf_distil_bert_model[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          98432       global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 32)           4128        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 6)            198         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 66,465,638\n",
      "Trainable params: 66,465,638\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "195cd655-6f4a-4ca3-93a0-d3f9bbff0aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d59e4749-2529-490c-bd02-a168f2f9d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-5)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()  # categorical = one-hot\n",
    "# acc = tf.keras.metrics.CategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eeefac32-d6b5-4354-8052-e7cac50197b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "389/389 [==============================] - 118s 288ms/step - loss: 0.9794 - accuracy: 0.6634 - val_loss: 0.4104 - val_accuracy: 0.8763\n",
      "Epoch 2/3\n",
      "389/389 [==============================] - 112s 288ms/step - loss: 0.3174 - accuracy: 0.8990 - val_loss: 0.2230 - val_accuracy: 0.9195\n",
      "Epoch 3/3\n",
      "389/389 [==============================] - 117s 300ms/step - loss: 0.1888 - accuracy: 0.9321 - val_loss: 0.1796 - val_accuracy: 0.9265\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(\n",
    "    x ={'input_ids':X_train['input_ids'],'attention_mask':X_train['attention_mask']} ,\n",
    "    y = to_categorical(df_train.Sentiment),\n",
    "    validation_data = (\n",
    "    {'input_ids':X_test['input_ids'],'attention_mask':X_test['attention_mask']}, to_categorical(df_test.Sentiment)\n",
    "    ),\n",
    "  epochs=3,\n",
    "    batch_size=36\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a96401-71bc-45d4-ad46-0f3859d4b867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738e674-8c69-4bed-a732-24b13cceca39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
